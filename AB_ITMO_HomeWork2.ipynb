{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4J9o80bN6bhq"
   },
   "source": [
    "# ДЗ 2:\n",
    "\n",
    "1. Применить ранговую трансформацию (потом t-test) и сравнить с результатами по Манну-Уитни на:\n",
    "- метрике cart_added_cnt (5 баллов)\n",
    "\n",
    "2. Реализовать cuped-трансформацию и сравнить мощность t-критерия на:\n",
    "- обычной метрике cart_added_cnt (5 баллов)\n",
    "- логарфимированной метрике cart_added_cnt (5 баллов)\n",
    "- метрике cart_added_cnt (а после подвергнуть ранговому преобразованию) (5 баллов)\n",
    "\n",
    "\n",
    "В каждом случае фиксировать, на сколько сокращается дисперсия, проверять равны ли средние в группах в ковариате и совпадают ли средние в метрике до и после применения cuped\n",
    "(+ 5 балла за обьяснения и выводы)\n",
    "\n",
    "\n",
    "3. Реализовать разбивку на бакеты любым (правильным) способом, оценить t-критерием и сравнить с результатом без бакетирования:\n",
    "- на логнормальном распределении (сгенерированные данные) (5 баллов)\n",
    "- на метрике cart_added_cnt (5 баллов)\n",
    "\n",
    "\n",
    "4. Реализовать постстратификацию на данных shop_metrics_old для метрики cart_added_cnt:\n",
    "- на сочетании пола и возраста (возраст разбить на подгруппы: 18-24, 25-45, 46-60, 61-75, 76+) (5 баллов)\n",
    "подсчитать результаты для случая без постстратификации и с постстратификацией. (дисперсию и среднее)\n",
    "- проверить мощность и корректность t-критерия для постстратифицированного случая (5 баллов)\n",
    "\n",
    "\n",
    "(+ 5 балла за обьяснения и выводы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v7Y9yrjgE2Dq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leftg\\Desktop\\AB\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import hashlib\n",
    "from base64 import b64encode\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_metrics_new = pd.read_csv('shop_df_metrics_dec.csv').drop(columns='Unnamed: 0')\n",
    "shop_metrics_old = pd.read_csv('shop_df_metrics_sept.csv').drop(columns='Unnamed: 0')\n",
    "shop_users_info = pd.read_csv('shop_df_users.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_generator(salt=None):\n",
    "    if salt is None:\n",
    "        salt = os.urandom(8)\n",
    "    return b64encode(salt).decode('ascii')\n",
    "\n",
    "def groups_splitter(df, user_salt=None):\n",
    "    if user_salt is None:\n",
    "        salt = salt_generator()\n",
    "    else:\n",
    "        salt = user_salt\n",
    "    df = df.copy()\n",
    "    df['hash'] = ((df['user_id'].astype(str)) + '#' + salt).apply(\n",
    "        lambda x: hashlib.sha256(x.encode('utf-8')).hexdigest()\n",
    "    )\n",
    "    df['group'] = ((df['hash'].str.slice(start=-6).apply(int, base=16) % 2)\n",
    "                   .map(lambda x: 'A' if x == 0 else 'B'))\n",
    "    return df[['user_id', 'group']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1: Ранговая трансформация + t-test vs Манна-Уитни\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rank transformation:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rank transformation: 100%|██████████| 100/100 [01:32<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная метрика: p-value = 0.4962, mannwhitney p-value = 0.4684\n",
      "T-test на рангах: p-value = 0.4684\n",
      "Манна-Уитни и t-test на рангах дают одинаковый результат\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def rank_transformation(df_a, df_b, metric):\n",
    "    df = pd.concat([df_a, df_b], axis=0)\n",
    "    df['rank'] = df[metric].rank(method='average')\n",
    "    return df\n",
    "\n",
    "pvalues_orig = []\n",
    "pvalues_rank = []\n",
    "pvalues_mannwhitney = []\n",
    "shop_base = shop_metrics_new[['user_id', 'cart_added_cnt']].copy()\n",
    "for i in tqdm(range(100), desc=\"Rank transformation\"):\n",
    "    new_group = groups_splitter(shop_base.copy(), user_salt=salt_generator())\n",
    "    new_df = pd.merge(shop_base, new_group, on='user_id', how='left')\n",
    "    df_a_new = new_df[new_df['group'] == 'A']\n",
    "    df_b_new = new_df[new_df['group'] == 'B']\n",
    "    metric_a_new = df_a_new['cart_added_cnt']\n",
    "    metric_b_new = df_b_new['cart_added_cnt']\n",
    "    t_orig = stats.ttest_ind(metric_a_new, metric_b_new)\n",
    "    pvalues_orig.append(t_orig.pvalue)\n",
    "    ranked_new = rank_transformation(df_a_new, df_b_new, 'cart_added_cnt')\n",
    "    rank_a_new = ranked_new[ranked_new['group'] == 'A']['rank']\n",
    "    rank_b_new = ranked_new[ranked_new['group'] == 'B']['rank']\n",
    "    t_rank = stats.ttest_ind(rank_a_new, rank_b_new)\n",
    "    pvalues_rank.append(t_rank.pvalue)\n",
    "    mw = stats.mannwhitneyu(metric_a_new, metric_b_new, alternative='two-sided')\n",
    "    pvalues_mannwhitney.append(mw.pvalue)\n",
    "\n",
    "orig_t_test = np.mean(pvalues_orig)\n",
    "mannwhitney_p_value = np.mean(pvalues_mannwhitney)\n",
    "rank_t_test = np.mean(pvalues_rank)\n",
    "\n",
    "print(f\"Исходная метрика: p-value = {orig_t_test:.4f}, mannwhitney p-value = {mannwhitney_p_value:.4f}\")\n",
    "print(f\"T-test на рангах: p-value = {rank_t_test:.4f}\")\n",
    "\n",
    "if np.round(mannwhitney_p_value, 5) == np.round(rank_t_test, 5):\n",
    "    print(\"Манна-Уитни и t-test на рангах дают одинаковый результат\")\n",
    "else:\n",
    "    print(\"Манна-Уитни и t-test на рангах дают разный результат\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2: CUPED-трансформация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ковариата: A = 0.1406, B = 0.1434, p-value = 0.3065\n",
      "Ковариата сбалансирована\n"
     ]
    }
   ],
   "source": [
    "def cuped_transform(df, metrics, covariates=None):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if covariates is None:\n",
    "        covariates = {m: str(m)+'_covariate' for m in metrics}\n",
    "    \n",
    "    new_columns = [str(m)+'_cuped' for m in metrics]\n",
    "    for col in new_columns:\n",
    "        df[col] = 0.0\n",
    "\n",
    "    df_mini = df.fillna(0)\n",
    "    theta_dict = {}\n",
    "    \n",
    "    for m in metrics:\n",
    "        if m not in covariates:\n",
    "            covariate_column = str(m)+'_covariate'\n",
    "        else:\n",
    "            covariate_column = covariates[m]\n",
    "        cuped_column = str(m)+'_cuped'\n",
    "        \n",
    "        if covariate_column not in df_mini.columns:\n",
    "            raise KeyError(f\"Колонка '{covariate_column}' не найдена в датафрейме.\")\n",
    "        \n",
    "        mean_covariate = df_mini[covariate_column].mean()\n",
    "\n",
    "        theta = (df_mini[m].cov(df_mini[covariate_column]))/(df_mini.loc[:,covariate_column].var())\n",
    "        theta_dict[m] = theta\n",
    "        df_mini[cuped_column] = df_mini[m] - (df_mini[covariate_column] - mean_covariate) * theta\n",
    "\n",
    "    df.update(df_mini)\n",
    "\n",
    "    return df.drop_duplicates(), theta_dict\n",
    "\n",
    "shop_metrics_old_renamed = shop_metrics_old[['user_id', 'cart_added_cnt']].rename(\n",
    "    columns={'cart_added_cnt': 'cart_added_cnt_covariate'}\n",
    ")\n",
    "shop_metrics_merged = pd.merge(\n",
    "    shop_metrics_new[['user_id', 'group', 'cart_added_cnt']],\n",
    "    shop_metrics_old_renamed,\n",
    "    on='user_id',\n",
    "    how='left'\n",
    ")\n",
    "shop_metrics_merged['cart_added_cnt_covariate'] = shop_metrics_merged['cart_added_cnt_covariate'].fillna(0)\n",
    "\n",
    "cov_a = shop_metrics_merged[shop_metrics_merged['group'] == 'A']['cart_added_cnt_covariate']\n",
    "cov_b = shop_metrics_merged[shop_metrics_merged['group'] == 'B']['cart_added_cnt_covariate']\n",
    "t_test_cov = stats.ttest_ind(cov_a, cov_b).pvalue\n",
    "\n",
    "\n",
    "print(f\"Ковариата: A = {cov_a.mean():.4f}, B = {cov_b.mean():.4f}, p-value = {t_test_cov:.4f}\")\n",
    "if t_test_cov > 0.05:\n",
    "    print(\"Ковариата сбалансирована\")\n",
    "else:\n",
    "    print(\"Ковариата не сбалансирована\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cuped_results(df_original, df_cuped, metric_name, cuped_suffix='_cuped', theta=None):\n",
    "    \"\"\"Анализирует результаты CUPED трансформации\"\"\"\n",
    "    metric_a_orig = df_original[df_original['group'] == 'A'][metric_name]\n",
    "    metric_b_orig = df_original[df_original['group'] == 'B'][metric_name]\n",
    "    metric_a_cuped = df_cuped[df_cuped['group'] == 'A'][metric_name + cuped_suffix]\n",
    "    metric_b_cuped = df_cuped[df_cuped['group'] == 'B'][metric_name + cuped_suffix]\n",
    "    \n",
    "    var_reduction_a = (1 - metric_a_cuped.var() / metric_a_orig.var()) * 100\n",
    "    var_reduction_b = (1 - metric_b_cuped.var() / metric_b_orig.var()) * 100\n",
    "    mean_diff_a = abs(metric_a_orig.mean() - metric_a_cuped.mean())\n",
    "    mean_diff_b = abs(metric_b_orig.mean() - metric_b_cuped.mean())\n",
    "    \n",
    "    t_test_orig = stats.ttest_ind(metric_a_orig, metric_b_orig)\n",
    "    t_test_cuped = stats.ttest_ind(metric_a_cuped, metric_b_cuped)\n",
    "    \n",
    "    print(f\"Средние: до CUPED A = {metric_a_orig.mean():.4f}, B = {metric_b_orig.mean():.4f}\")\n",
    "    print(f\"Средние: после CUPED A = {metric_a_cuped.mean():.4f}, B = {metric_b_cuped.mean():.4f}\")\n",
    "    print(f\"Разница средних: A = {mean_diff_a:.4f}, B = {mean_diff_b:.4f}\")\n",
    "    \n",
    "    print(f\"Дисперсии: до CUPED A = {metric_a_orig.var():.4f}, B = {metric_b_orig.var():.4f}\")\n",
    "    print(f\"Дисперсии: после CUPED A = {metric_a_cuped.var():.4f}, B = {metric_b_cuped.var():.4f}\")\n",
    "    print(f\"Сокращение дисперсии: A = {var_reduction_a:.2f}%, B = {var_reduction_b:.2f}%\")\n",
    "    \n",
    "    print(f\"T-test: до CUPED p-value = {t_test_orig.pvalue:.4f}, после CUPED p-value = {t_test_cuped.pvalue:.4f}\")\n",
    "    if theta is not None:\n",
    "        print(f\"Theta = {theta:.4f}\")\n",
    "    \n",
    "    return t_test_orig, t_test_cuped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. CUPED на обычной метрике cart_added_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средние: до CUPED A = 0.1350, B = 0.1386\n",
      "Средние: после CUPED A = 0.1364, B = 0.1372\n",
      "Разница средних: A = 0.0013, B = 0.0013\n",
      "Дисперсии: до CUPED A = 0.3806, B = 0.4247\n",
      "Дисперсии: после CUPED A = 0.0182, B = 0.0215\n",
      "Сокращение дисперсии: A = 95.21%, B = 94.94%\n",
      "T-test: до CUPED p-value = 0.1920, после CUPED p-value = 0.1659\n",
      "Theta = 0.9350\n"
     ]
    }
   ],
   "source": [
    "df_cuped_original, theta_dict_original = cuped_transform(shop_metrics_merged.copy(), ['cart_added_cnt'])\n",
    "theta_original = theta_dict_original['cart_added_cnt']\n",
    "\n",
    "t_test_orig_2a, t_test_cuped_2a = analyze_cuped_results(\n",
    "    shop_metrics_merged, \n",
    "    df_cuped_original, \n",
    "    'cart_added_cnt', \n",
    "    theta=theta_original\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. CUPED на логарифмированной метрике cart_added_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средние: до CUPED A = 0.0797, B = 0.0813\n",
      "Средние: после CUPED A = 0.0803, B = 0.0807\n",
      "Разница средних: A = 0.0006, B = 0.0006\n",
      "Дисперсии: до CUPED A = 0.0647, B = 0.0663\n",
      "Дисперсии: после CUPED A = 0.0021, B = 0.0018\n",
      "Сокращение дисперсии: A = 96.82%, B = 97.35%\n",
      "T-test: до CUPED p-value = 0.1460, после CUPED p-value = 0.0404\n",
      "Theta = 0.9665\n"
     ]
    }
   ],
   "source": [
    "df_log = shop_metrics_merged.copy()\n",
    "df_log['cart_added_cnt_ln'] = np.log(df_log['cart_added_cnt'] + 1)\n",
    "df_log['cart_added_cnt_covariate_ln'] = np.log(df_log['cart_added_cnt_covariate'] + 1)\n",
    "\n",
    "df_cuped_log, theta_dict_log = cuped_transform(df_log.copy(), ['cart_added_cnt_ln'], {'cart_added_cnt_ln': 'cart_added_cnt_covariate_ln'})\n",
    "theta_log = theta_dict_log['cart_added_cnt_ln']\n",
    "\n",
    "t_test_orig_2b, t_test_cuped_2b = analyze_cuped_results(\n",
    "    df_log, \n",
    "    df_cuped_log, \n",
    "    'cart_added_cnt_ln', \n",
    "    theta=theta_log\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. CUPED на ранговой метрике cart_added_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средние: до CUPED A = 111170.4563, B = 111351.6422\n",
      "Средние: после CUPED A = 111242.9144, B = 111279.1052\n",
      "Разница средних: A = 72.4581, B = 72.5370\n",
      "Дисперсии: до CUPED A = 1116108735.2908, B = 1132936846.7436\n",
      "Дисперсии: после CUPED A = 27188807.8374, B = 23441920.6708\n",
      "Сокращение дисперсии: A = 97.56%, B = 97.93%\n",
      "T-test: до CUPED p-value = 0.2025, после CUPED p-value = 0.0898\n",
      "Theta = 0.9798\n"
     ]
    }
   ],
   "source": [
    "df_rank = shop_metrics_merged.copy()\n",
    "df_a_rank = df_rank[df_rank['group'] == 'A'].copy()\n",
    "df_b_rank = df_rank[df_rank['group'] == 'B'].copy()\n",
    "\n",
    "ranked_full = rank_transformation(df_a_rank, df_b_rank, 'cart_added_cnt')\n",
    "df_rank = ranked_full[['user_id', 'group', 'cart_added_cnt', 'rank', 'cart_added_cnt_covariate']].copy()\n",
    "ranked_cov = rank_transformation(df_a_rank, df_b_rank, 'cart_added_cnt_covariate')\n",
    "df_rank['rank_covariate'] = ranked_cov['rank']\n",
    "\n",
    "df_cuped_rank, theta_dict_rank = cuped_transform(df_rank.copy(), ['rank'])\n",
    "theta_rank = theta_dict_rank['rank']\n",
    "\n",
    "t_test_orig_2c, t_test_cuped_2c = analyze_cuped_results(\n",
    "    df_rank, \n",
    "    df_cuped_rank, \n",
    "    'rank', \n",
    "    theta=theta_rank\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Проверка мощности и корректности t-критерия для CUPED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Оригинал:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Оригинал: 100%|██████████| 100/100 [01:26<00:00,  1.16it/s]\n",
      "Логарифм: 100%|██████████| 100/100 [01:27<00:00,  1.14it/s]\n",
      "Ранг: 100%|██████████| 100/100 [01:32<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оригинал: мощность = 100.0%, корректность = 97.0%\n",
      "Логарифм: мощность = 100.0%, корректность = 93.0%\n",
      "Ранг: мощность = 100.0%, корректность = 95.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def check_power_correctness(df_base, metric_col, group_col='group', effect_size=1.05, n_iterations=100, desc=None):\n",
    "    correctness = []\n",
    "    power = []\n",
    "    shop_base = df_base.drop(columns=[group_col] if group_col in df_base.columns else [])\n",
    "    \n",
    "    if desc is None:\n",
    "        desc = f\"Проверка {metric_col}\"\n",
    "    \n",
    "    for i in tqdm(range(n_iterations), desc=desc):\n",
    "        new_group = groups_splitter(shop_base.copy(), user_salt=salt_generator())\n",
    "        new_df = pd.merge(\n",
    "            df_base.drop(columns=[group_col] if group_col in df_base.columns else []),\n",
    "            new_group, \n",
    "            how=\"left\", \n",
    "            on=['user_id']\n",
    "        ).drop_duplicates()\n",
    "        \n",
    "        vec_a = new_df[new_df['group'] == 'A'][metric_col]\n",
    "        vec_b = new_df[new_df['group'] == 'B'][metric_col]\n",
    "        vec_b_effect = vec_b * effect_size\n",
    "        \n",
    "        p_cor = stats.ttest_ind(vec_a, vec_b)[1]\n",
    "        correctness.append(p_cor)\n",
    "        p_power = stats.ttest_ind(vec_a, vec_b_effect)[1]\n",
    "        power.append(p_power)\n",
    "    \n",
    "    correctness = np.array(correctness)\n",
    "    power = np.array(power)\n",
    "    power_rate = (power[power < 0.05].shape[0] / power.shape[0]) * 100\n",
    "    correctness_rate = (1 - (correctness[correctness < 0.05].shape[0] / correctness.shape[0])) * 100\n",
    "    \n",
    "    return {'power': power_rate, 'correctness': correctness_rate}\n",
    "\n",
    "\n",
    "results_power_2a = check_power_correctness(\n",
    "    df_cuped_original[['user_id', 'group', 'cart_added_cnt_cuped']].rename(\n",
    "        columns={'cart_added_cnt_cuped': 'metric'}\n",
    "    ),\n",
    "    'metric', \n",
    "    n_iterations=100,\n",
    "    desc='Оригинал'\n",
    ")\n",
    "\n",
    "results_power_2b = check_power_correctness(\n",
    "    df_cuped_log[['user_id', 'group', 'cart_added_cnt_ln_cuped']].rename(\n",
    "        columns={'cart_added_cnt_ln_cuped': 'metric'}\n",
    "    ),\n",
    "    'metric', \n",
    "    n_iterations=100,\n",
    "    desc='Логарифм'\n",
    ")\n",
    "\n",
    "results_power_2c = check_power_correctness(\n",
    "    df_cuped_rank[['user_id', 'group', 'rank_cuped']].rename(\n",
    "        columns={'rank_cuped': 'metric'}\n",
    "    ),\n",
    "    'metric', \n",
    "    n_iterations=100,\n",
    "    desc='Ранг'\n",
    ")\n",
    "\n",
    "print(f\"Оригинал: мощность = {results_power_2a['power']:.1f}%, корректность = {results_power_2a['correctness']:.1f}%\")\n",
    "print(f\"Логарифм: мощность = {results_power_2b['power']:.1f}%, корректность = {results_power_2b['correctness']:.1f}%\")\n",
    "print(f\"Ранг: мощность = {results_power_2c['power']:.1f}%, корректность = {results_power_2c['correctness']:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3: Бакетирование\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_metric(df, metric_col, group_col='group', n_buckets=10, method='quantile'):\n",
    "    df = df.copy()\n",
    "    if method == 'quantile':\n",
    "        df['bucket'] = pd.qcut(df[metric_col], q=n_buckets, duplicates='drop', labels=False)\n",
    "    else:\n",
    "        df['bucket'] = pd.cut(df[metric_col], bins=n_buckets, labels=False, duplicates='drop')\n",
    "    \n",
    "    bucketed = df.groupby([group_col, 'bucket'])[metric_col].agg(['mean', 'count']).reset_index()\n",
    "    bucketed.columns = [group_col, 'bucket', 'metric_mean', 'count']\n",
    "    return bucketed\n",
    "\n",
    "def ttest_bucketed(bucketed_df, group_col='group'):\n",
    "    group_a = bucketed_df[bucketed_df[group_col] == 'A']\n",
    "    group_b = bucketed_df[bucketed_df[group_col] == 'B']\n",
    "    metric_a = group_a['metric_mean']\n",
    "    metric_b = group_b['metric_mean']\n",
    "    return stats.ttest_ind(metric_a, metric_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Бакетирование на логнормальном распределении\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bucketing lognormal: 100%|██████████| 100/100 [00:01<00:00, 59.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без бакетирования: p-value = 0.4673, A = 12.1519, B = 12.1727\n",
      "С бакетированием: p-value = 0.9776, A = 12.1472, B = 12.1767, бакетов = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_samples = 10000\n",
    "mu, sigma = 2.0, 1.0\n",
    "\n",
    "pvalues_no_bucket = []\n",
    "pvalues_bucket = []\n",
    "means_a_no_bucket = []\n",
    "means_b_no_bucket = []\n",
    "means_a_bucket = []\n",
    "means_b_bucket = []\n",
    "for i in tqdm(range(100), desc=\"Bucketing lognormal\"):\n",
    "    data_a_new = np.random.lognormal(mean=mu, sigma=sigma, size=n_samples // 2)\n",
    "    data_b_new = np.random.lognormal(mean=mu, sigma=sigma, size=n_samples // 2)\n",
    "    t_no_bucket = stats.ttest_ind(data_a_new, data_b_new)\n",
    "    pvalues_no_bucket.append(t_no_bucket.pvalue)\n",
    "    means_a_no_bucket.append(data_a_new.mean())\n",
    "    means_b_no_bucket.append(data_b_new.mean())\n",
    "    df_new = pd.DataFrame({\n",
    "        'user_id': range(n_samples),\n",
    "        'group': ['A'] * (n_samples // 2) + ['B'] * (n_samples // 2),\n",
    "        'metric': np.concatenate([data_a_new, data_b_new])\n",
    "    })\n",
    "    bucketed_new = bucket_metric(df_new, 'metric', n_buckets=20, method='quantile')\n",
    "    t_bucket = ttest_bucketed(bucketed_new)\n",
    "    pvalues_bucket.append(t_bucket.pvalue)\n",
    "    means_a_bucket.append(bucketed_new[bucketed_new['group'] == 'A']['metric_mean'].mean())\n",
    "    means_b_bucket.append(bucketed_new[bucketed_new['group'] == 'B']['metric_mean'].mean())\n",
    "\n",
    "t_test_no_bucket = np.mean(pvalues_no_bucket)\n",
    "t_test_bucket = np.mean(pvalues_bucket)\n",
    "mean_a = np.mean(means_a_no_bucket)\n",
    "mean_b = np.mean(means_b_no_bucket)\n",
    "mean_a_b = np.mean(means_a_bucket)\n",
    "mean_b_b = np.mean(means_b_bucket)\n",
    "\n",
    "print(f\"Без бакетирования: p-value = {t_test_no_bucket:.4f}, A = {mean_a:.4f}, B = {mean_b:.4f}\")\n",
    "print(f\"С бакетированием: p-value = {t_test_bucket:.4f}, A = {mean_a_b:.4f}, B = {mean_b_b:.4f}, бакетов = 20\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Бакетирование на метрике cart_added_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bucketing cart_added_cnt: 100%|██████████| 100/100 [03:35<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без бакетирования: p-value = 0.5192, A = 0.1371, B = 0.1365, дисперсия A = 0.4146, B = 0.3907\n",
      "С бакетированием: p-value = 0.9852, A = 1.5751, B = 1.5599, бакетов = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pvalues_no_bucket_cart = []\n",
    "pvalues_bucket_cart = []\n",
    "means_a_no_bucket = []\n",
    "means_b_no_bucket = []\n",
    "vars_a_no_bucket = []\n",
    "vars_b_no_bucket = []\n",
    "means_a_bucket = []\n",
    "means_b_bucket = []\n",
    "shop_base_cart = shop_metrics_new[['user_id', 'cart_added_cnt']].copy()\n",
    "for i in tqdm(range(100), desc=\"Bucketing cart_added_cnt\"):\n",
    "    new_group = groups_splitter(shop_base_cart.copy(), user_salt=salt_generator())\n",
    "    new_df_cart = pd.merge(shop_base_cart, new_group, on='user_id', how='left')\n",
    "    metric_a_new = new_df_cart[new_df_cart['group'] == 'A']['cart_added_cnt']\n",
    "    metric_b_new = new_df_cart[new_df_cart['group'] == 'B']['cart_added_cnt']\n",
    "    t_no_bucket = stats.ttest_ind(metric_a_new, metric_b_new)\n",
    "    pvalues_no_bucket_cart.append(t_no_bucket.pvalue)\n",
    "    means_a_no_bucket.append(metric_a_new.mean())\n",
    "    means_b_no_bucket.append(metric_b_new.mean())\n",
    "    vars_a_no_bucket.append(metric_a_new.var())\n",
    "    vars_b_no_bucket.append(metric_b_new.var())\n",
    "    bucketed_new = bucket_metric(new_df_cart, 'cart_added_cnt', n_buckets=20, method='quantile')\n",
    "    t_bucket = ttest_bucketed(bucketed_new)\n",
    "    pvalues_bucket_cart.append(t_bucket.pvalue)\n",
    "    means_a_bucket.append(bucketed_new[bucketed_new['group'] == 'A']['metric_mean'].mean())\n",
    "    means_b_bucket.append(bucketed_new[bucketed_new['group'] == 'B']['metric_mean'].mean())\n",
    "\n",
    "t_test_no_bucket_cart = np.mean(pvalues_no_bucket_cart)\n",
    "t_test_bucket_cart = np.mean(pvalues_bucket_cart)\n",
    "mean_a_cart = np.mean(means_a_no_bucket)\n",
    "mean_b_cart = np.mean(means_b_no_bucket)\n",
    "var_a_cart = np.mean(vars_a_no_bucket)\n",
    "var_b_cart = np.mean(vars_b_no_bucket)\n",
    "mean_a_b_cart = np.mean(means_a_bucket)\n",
    "mean_b_b_cart = np.mean(means_b_bucket)\n",
    "\n",
    "print(f\"Без бакетирования: p-value = {t_test_no_bucket_cart:.4f}, A = {mean_a_cart:.4f}, B = {mean_b_cart:.4f}, дисперсия A = {var_a_cart:.4f}, B = {var_b_cart:.4f}\")\n",
    "print(f\"С бакетированием: p-value = {t_test_bucket_cart:.4f}, A = {mean_a_b_cart:.4f}, B = {mean_b_b_cart:.4f}, бакетов = 20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4: Постстратификация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по стратам:\n",
      "strat\n",
      "m_25-45    42086\n",
      "m_46-60    29693\n",
      "m_61-75    29607\n",
      "f_25-45    27881\n",
      "f_46-60    19955\n",
      "f_61-75    19882\n",
      "m_76+      17849\n",
      "m_18-24    14077\n",
      "f_76+      12154\n",
      "f_18-24     9337\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_strat = pd.merge(\n",
    "    shop_metrics_old[['user_id', 'cart_added_cnt']],\n",
    "    shop_users_info[['user_id', 'user_age', 'user_sex']],\n",
    "    on='user_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "def create_age_group(age):\n",
    "    if pd.isna(age):\n",
    "        return 'unknown'\n",
    "    elif age < 18:\n",
    "        return 'under_18'\n",
    "    elif 18 <= age <= 24:\n",
    "        return '18-24'\n",
    "    elif 25 <= age <= 45:\n",
    "        return '25-45'\n",
    "    elif 46 <= age <= 60:\n",
    "        return '46-60'\n",
    "    elif 61 <= age <= 75:\n",
    "        return '61-75'\n",
    "    else:\n",
    "        return '76+'\n",
    "\n",
    "df_strat['age_group'] = df_strat['user_age'].apply(create_age_group)\n",
    "group_mapping = shop_metrics_new[['user_id', 'group']].set_index('user_id')['group'].to_dict()\n",
    "df_strat['group'] = df_strat['user_id'].map(group_mapping)\n",
    "df_strat = df_strat.dropna(subset=['group'])\n",
    "\n",
    "df_strat['strat'] = df_strat['user_sex'].astype(str) + '_' + df_strat['age_group'].astype(str)\n",
    "\n",
    "print(\"Распределение по стратам:\")\n",
    "print(df_strat['strat'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Результаты без постстратификации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без постстратификации: A среднее = 0.1406, дисперсия = 0.4114, n = 111321\n",
      "Без постстратификации: B среднее = 0.1434, дисперсия = 0.4643, n = 111200\n",
      "T-test: p-value = 0.3065, эффект = 2.04%\n"
     ]
    }
   ],
   "source": [
    "metric_a_no_strat = df_strat[df_strat['group'] == 'A']['cart_added_cnt']\n",
    "metric_b_no_strat = df_strat[df_strat['group'] == 'B']['cart_added_cnt']\n",
    "t_test_no_strat = stats.ttest_ind(metric_a_no_strat, metric_b_no_strat)\n",
    "\n",
    "print(f\"Без постстратификации: A среднее = {metric_a_no_strat.mean():.4f}, дисперсия = {metric_a_no_strat.var():.4f}, n = {len(metric_a_no_strat)}\")\n",
    "print(f\"Без постстратификации: B среднее = {metric_b_no_strat.mean():.4f}, дисперсия = {metric_b_no_strat.var():.4f}, n = {len(metric_b_no_strat)}\")\n",
    "print(f\"T-test: p-value = {t_test_no_strat.pvalue:.4f}, эффект = {((metric_b_no_strat.mean() - metric_a_no_strat.mean()) / metric_a_no_strat.mean() * 100):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Результаты с постстратификацией\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С постстратификацией: A среднее = 0.1406, дисперсия = 0.4116, сокращение = -0.05%\n",
      "С постстратификацией: B среднее = 0.1434, дисперсия = 0.4642, сокращение = 0.02%\n",
      "T-test: p-value = 0.3089, эффект = 2.03%\n",
      "Сравнение средних: A 0.1406 -> 0.1406, B 0.1434 -> 0.1434\n"
     ]
    }
   ],
   "source": [
    "N_total = len(df_strat)\n",
    "strata_weights = df_strat['strat'].value_counts() / N_total\n",
    "strata_stats = df_strat.groupby(['group', 'strat'])['cart_added_cnt'].agg(['mean', 'var', 'count']).reset_index()\n",
    "strata_stats.columns = ['group', 'strat', 'mean', 'var', 'count']\n",
    "\n",
    "mean_a_strat = 0\n",
    "mean_b_strat = 0\n",
    "var_a_strat = 0\n",
    "var_b_strat = 0\n",
    "\n",
    "for strat in strata_weights.index:\n",
    "    weight = strata_weights[strat]\n",
    "    stats_a = strata_stats[(strata_stats['group'] == 'A') & (strata_stats['strat'] == strat)]\n",
    "    if len(stats_a) > 0:\n",
    "        mean_a_strat += stats_a.iloc[0]['mean'] * weight\n",
    "        var_a_strat += stats_a.iloc[0]['var'] * weight\n",
    "    \n",
    "    stats_b = strata_stats[(strata_stats['group'] == 'B') & (strata_stats['strat'] == strat)]\n",
    "    if len(stats_b) > 0:\n",
    "        mean_b_strat += stats_b.iloc[0]['mean'] * weight\n",
    "        var_b_strat += stats_b.iloc[0]['var'] * weight\n",
    "\n",
    "n_a = len(metric_a_no_strat)\n",
    "n_b = len(metric_b_no_strat)\n",
    "std_a_strat = np.sqrt(var_a_strat)\n",
    "std_b_strat = np.sqrt(var_b_strat)\n",
    "\n",
    "t_test_strat = stats.ttest_ind_from_stats(\n",
    "    mean_a_strat, std_a_strat, n_a,\n",
    "    mean_b_strat, std_b_strat, n_b\n",
    ")\n",
    "\n",
    "var_reduction_a_strat = (1 - var_a_strat / metric_a_no_strat.var()) * 100\n",
    "var_reduction_b_strat = (1 - var_b_strat / metric_b_no_strat.var()) * 100\n",
    "\n",
    "print(f\"С постстратификацией: A среднее = {mean_a_strat:.4f}, дисперсия = {var_a_strat:.4f}, сокращение = {var_reduction_a_strat:.2f}%\")\n",
    "print(f\"С постстратификацией: B среднее = {mean_b_strat:.4f}, дисперсия = {var_b_strat:.4f}, сокращение = {var_reduction_b_strat:.2f}%\")\n",
    "print(f\"T-test: p-value = {t_test_strat.pvalue:.4f}, эффект = {((mean_b_strat - mean_a_strat) / mean_a_strat * 100):.2f}%\")\n",
    "print(f\"Сравнение средних: A {metric_a_no_strat.mean():.4f} -> {mean_a_strat:.4f}, B {metric_b_no_strat.mean():.4f} -> {mean_b_strat:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Проверка мощности и корректности t-критерия для постстратификации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Постстратификация: 100%|██████████| 100/100 [02:02<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мощность = 99.0%, корректность = 96.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def stratified_ttest(df, metric_col='cart_added_cnt', group_col='group', strat_col='strat', effect_size=1.05):\n",
    "    N_total = len(df)\n",
    "    strata_weights = df[strat_col].value_counts() / N_total\n",
    "    strata_stats = df.groupby([group_col, strat_col])[metric_col].agg(['mean', 'var', 'count']).reset_index()\n",
    "    strata_stats.columns = [group_col, strat_col, 'mean', 'var', 'count']\n",
    "\n",
    "    mean_a = 0\n",
    "    mean_b = 0\n",
    "    var_a = 0\n",
    "    var_b = 0\n",
    "\n",
    "    for strat in strata_weights.index:\n",
    "        weight = strata_weights[strat]\n",
    "\n",
    "        stats_a = strata_stats[(strata_stats[group_col] == 'A') & (strata_stats[strat_col] == strat)]\n",
    "        stats_b = strata_stats[(strata_stats[group_col] == 'B') & (strata_stats[strat_col] == strat)]\n",
    "\n",
    "        if len(stats_a) == 0 or len(stats_b) == 0:\n",
    "            continue\n",
    "\n",
    "        var_a_val = stats_a.iloc[0]['var']\n",
    "        var_b_val = stats_b.iloc[0]['var']\n",
    "\n",
    "        if np.isnan(var_a_val):\n",
    "            var_a_val = 0\n",
    "        if np.isnan(var_b_val):\n",
    "            var_b_val = 0\n",
    "\n",
    "        mean_a += stats_a.iloc[0]['mean'] * weight\n",
    "        var_a += var_a_val * weight\n",
    "\n",
    "        mean_b += stats_b.iloc[0]['mean'] * weight\n",
    "        var_b += var_b_val * weight\n",
    "\n",
    "    mean_b_effect = mean_b * effect_size\n",
    "    n_a = len(df[df[group_col] == 'A'])\n",
    "    n_b = len(df[df[group_col] == 'B'])\n",
    "    std_a = np.sqrt(var_a)\n",
    "    std_b = np.sqrt(var_b)\n",
    "\n",
    "    t_test_aa = stats.ttest_ind_from_stats(mean_a, std_a, n_a, mean_b, std_b, n_b)\n",
    "    t_test_ab = stats.ttest_ind_from_stats(mean_a, std_a, n_a, mean_b_effect, std_b, n_b)\n",
    "\n",
    "    return t_test_aa.pvalue, t_test_ab.pvalue\n",
    "\n",
    "\n",
    "correctness_strat = []\n",
    "power_strat = []\n",
    "shop_base_strat = df_strat.drop(columns=['group'])\n",
    "\n",
    "for i in tqdm(range(100), desc=\"Постстратификация\"):\n",
    "    new_group = groups_splitter(shop_base_strat.copy(), user_salt=salt_generator())\n",
    "    new_df_strat = pd.merge(\n",
    "        shop_base_strat,\n",
    "        new_group,\n",
    "        how=\"left\",\n",
    "        on=['user_id']\n",
    "    ).drop_duplicates()\n",
    "    \n",
    "    if 'strat' not in new_df_strat.columns:\n",
    "        new_df_strat['strat'] = new_df_strat['user_sex'].astype(str) + '_' + new_df_strat['age_group'].astype(str)\n",
    "\n",
    "    mask_b = new_df_strat['group'] == 'B'\n",
    "    new_df_strat_effect = new_df_strat.copy()\n",
    "    new_df_strat_effect['cart_added_cnt'] = new_df_strat_effect['cart_added_cnt'].astype(float)\n",
    "    new_df_strat_effect.loc[mask_b, 'cart_added_cnt'] *= 1.05\n",
    "\n",
    "    p_cor, _ = stratified_ttest(new_df_strat, effect_size=1.0)\n",
    "    correctness_strat.append(p_cor)\n",
    "\n",
    "    _, p_power = stratified_ttest(new_df_strat_effect, effect_size=1.05)\n",
    "    power_strat.append(p_power)\n",
    "\n",
    "correctness_strat = np.array(correctness_strat)\n",
    "power_strat = np.array(power_strat)\n",
    "\n",
    "power_rate_strat = (power_strat[power_strat < 0.05].shape[0] / power_strat.shape[0]) * 100\n",
    "correctness_rate_strat = (1 - (correctness_strat[correctness_strat < 0.05].shape[0] / correctness_strat.shape[0])) * 100\n",
    "\n",
    "print(f\"Мощность = {power_rate_strat:.1f}%, корректность = {correctness_rate_strat:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговые выводы\n",
    "\n",
    "**Ранговая трансформация:**\n",
    "T-test на ранговых данных показал такой же результат, как и тест Манна-Уитни. Как следствие, его можно использовать если данные имеют распределение, отличное от нормального\n",
    "\n",
    "**CUPED:**\n",
    "Сильно снижает дисперсию. Ковариата сбалансирована. Лучше всего работает на логарифмированной метрике.\n",
    "\n",
    "**Бакетирование:**\n",
    "Снижает чувствительность теста, но защищает от выбросов. На логнормальных данных может скрыть реальные различия\n",
    "\n",
    "**Постстратификация:**\n",
    "Учитывает разные группы пользователей (пол, возраст). Средние почти не меняются, дисперсия немного меняется.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
